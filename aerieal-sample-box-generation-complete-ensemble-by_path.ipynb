{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An overview of generating bounding boxes from attention maps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the required libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import VOCSegmentation, VOCDetection\n",
    "from skimage.measure import label, regionprops\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50,resnet18, resnet34, resnet101, resnet152\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from activation_maps import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM\n",
    "from activation_maps.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_label={\n",
    " 0: 'broadleaved_indigenous_hardwood',\n",
    " 1: 'deciduous_hardwood',\n",
    " 2: 'grose_broom',\n",
    " 3: 'harvested_forest',\n",
    " 4: 'herbaceous_freshwater_vege',\n",
    " 5: 'high_producing_grassland',\n",
    " 6: 'indigenous_forest',\n",
    " 7: 'lake_pond',\n",
    " 8: 'low_producing_grassland',\n",
    " 9: 'manuka_kanuka',\n",
    " 10: 'shortrotation_cropland',\n",
    " 11: 'urban_build_up',\n",
    " 12: 'urban_parkland'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We open and display a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "import scipy as scipy\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision import datasets, models, transforms\n",
    "from shutil import copyfile\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/aerial_imagery2/classification\"\n",
    "val_data=datasets.ImageFolder(os.path.join(data_dir, 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet34\":\n",
    "        \"\"\" Resnet34\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet34(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet50\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet101\":\n",
    "        \"\"\" Resnet101\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet101(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet152\":\n",
    "        \"\"\" Resnet152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224    \n",
    "    \n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "    elif model_name == \"vits8\":\n",
    "        vits8 = torch.hub.load('facebookresearch/dino:main', 'dino_vits8')\n",
    "        model_ft = nn.Sequential(vits8,nn.Linear(384,num_classes))\n",
    "        input_size=224\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_from_model(model_path):\n",
    "    model0 = resnet18(pretrained=True)\n",
    "    num_ftrs = model0.fc.in_features\n",
    "    model0.fc = nn.Linear(num_ftrs, 13)\n",
    "    model0.load_state_dict(torch.load(model_path))\n",
    "    model0.eval()\n",
    "    target_layer = model0.layer4[-1]\n",
    "    cam = GradCAM(model=model0, target_layer=target_layer,use_cuda=True)\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_cam(cam_name, model, target_layer, use_cuda=False):\n",
    "    if cam_name == \"GradCAM\":\n",
    "        cam=GradCAM(model=model, target_layer=target_layer,use_cuda=use_cuda)\n",
    "    elif cam_name == \"ScoreCAM\":\n",
    "        cam=ScoreCAM(model=model, target_layer=target_layer,use_cuda=use_cuda)\n",
    "    elif cam_name ==\"GradCAMPlusPlus\":\n",
    "        cam=GradCAMPlusPlus(model=model, target_layer=target_layer,use_cuda=use_cuda)\n",
    "    elif cam_name == \"AblationCAM\":\n",
    "        cam=AblationCAM(model=model, target_layer=target_layer,use_cuda=use_cuda)\n",
    "    elif cam_name == \"XGradCAM\":\n",
    "        cam=XGradCAM(model=model, target_layer=target_layer,use_cuda=use_cuda)\n",
    "    else:\n",
    "        print(\"Invalid CAM method, exiting...\")\n",
    "        exit()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gscam_calc(camList,img,mylabel,mode=3):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    inv_normalize = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "        std=[1/0.229, 1/0.224, 1/0.255])\n",
    "    ])\n",
    " \n",
    "    img200=IOps.expand(img.resize((200,200)),12)\n",
    "    img200_0=ImChOps.offset(img200,12,12)\n",
    "    img200_1=ImChOps.offset(img200,0,12)\n",
    "    img200_2=ImChOps.offset(img200,-12,12)\n",
    "    img200_3=ImChOps.offset(img200,12,0)\n",
    "    img200_4=ImChOps.offset(img200,-12,0)\n",
    "    img200_5=ImChOps.offset(img200,12,-12)\n",
    "    img200_6=ImChOps.offset(img200,0,-12)\n",
    "    img200_7=ImChOps.offset(img200,-12,-12)\n",
    "\n",
    "    x = transform(img).unsqueeze(0)\n",
    "    x_0 =transform(img200_0).unsqueeze(0)\n",
    "    x_1 =transform(img200_1).unsqueeze(0)\n",
    "    x_2 =transform(img200_2).unsqueeze(0)\n",
    "    x_3 =transform(img200_3).unsqueeze(0)\n",
    "    x_4 =transform(img200_4).unsqueeze(0)\n",
    "    x_5 =transform(img200_5).unsqueeze(0)\n",
    "    x_6 =transform(img200_6).unsqueeze(0)\n",
    "    x_7 =transform(img200_7).unsqueeze(0)\n",
    "\n",
    "    x_y=torch.flip(x,[3])\n",
    "    x_x=torch.flip(x,[2])\n",
    "    x_xy=torch.flip(x,[2,3])\n",
    "    x_rot90=torch.rot90(x,1,[2,3])\n",
    "    x_rot270=torch.rot90(x,3,[2,3])\n",
    "    x_x_rot90=torch.rot90(x_x,1,[2,3])\n",
    "    x_y_rot90=torch.rot90(x_y,1,[2,3])\n",
    "    counter=0\n",
    "    grayscale_cam=np.zeros((224,224))\n",
    "    for thisCam in camList:\n",
    "        tempCam=thisCam(input_tensor=x,target_category=mylabel)\n",
    "        grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "        counter=counter+1\n",
    "        if mode>0:\n",
    "            tempCam = thisCam(input_tensor=x_x,target_category=mylabel)\n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_y,target_category=mylabel)\n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_xy,target_category=mylabel)\n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            counter=counter+3\n",
    "        if mode>1:\n",
    "            tempCam = thisCam(input_tensor=x_rot90,target_category=mylabel)\n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_rot270,target_category=mylabel)\n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_x_rot90,target_category=mylabel)\n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_y_rot90,target_category=mylabel)\n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            counter=counter+4\n",
    "        if mode>2:\n",
    "            tempCam = thisCam(input_tensor=x_0,target_category=mylabel)\n",
    "            tempCam = tempCam[24:224,24:224]\n",
    "            tempCam = sktransform.resize(tempCam,(224,224))    \n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_1,target_category=mylabel)\n",
    "            tempCam = tempCam[24:224,24:224]\n",
    "            tempCam = sktransform.resize(tempCam,(224,224))    \n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_2,target_category=mylabel)\n",
    "            tempCam = tempCam[24:224,24:224]\n",
    "            tempCam = sktransform.resize(tempCam,(224,224))    \n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_3,target_category=mylabel)\n",
    "            tempCam = tempCam[24:224,24:224]\n",
    "            tempCam = sktransform.resize(tempCam,(224,224))    \n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_4,target_category=mylabel)\n",
    "            tempCam = tempCam[24:224,24:224]\n",
    "            tempCam = sktransform.resize(tempCam,(224,224))    \n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_5,target_category=mylabel)\n",
    "            tempCam = tempCam[24:224,24:224]\n",
    "            tempCam = sktransform.resize(tempCam,(224,224))    \n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_6,target_category=mylabel)\n",
    "            tempCam = tempCam[24:224,24:224]\n",
    "            tempCam = sktransform.resize(tempCam,(224,224))    \n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            tempCam = thisCam(input_tensor=x_7,target_category=mylabel)\n",
    "            tempCam = tempCam[24:224,24:224]\n",
    "            tempCam = sktransform.resize(tempCam,(224,224))    \n",
    "            grayscale_cam=np.sum([grayscale_cam,tempCam],axis=0)\n",
    "            counter=counter+8\n",
    "    grayscale_cam=grayscale_cam/counter\n",
    "    return grayscale_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam0 = cam_from_model('aerial_small_auged_new_resnet18_13.pth')\n",
    "cam1 = cam_from_model('aerial_small_auged_new_resnet18_1.pth')\n",
    "cam2 = cam_from_model('aerial_small_auged_new_resnet18_29.pth')\n",
    "cam3 = cam_from_model('aerial_small_auged_new_resnet18_8.pth')\n",
    "cam4 = cam_from_model('aerial_small_auged_new_resnet18_6.pth')\n",
    "cam5 = cam_from_model('aerial_small_auged_new_resnet18_23.pth')\n",
    "cam6 = cam_from_model('aerial_small_auged_new_resnet18_24.pth')\n",
    "cam7 = cam_from_model('aerial_small_auged_new_resnet18_28.pth')\n",
    "cam8 = cam_from_model('aerial_small_auged_new_resnet18_12.pth')\n",
    "cam9 = cam_from_model('aerial_small_auged_new_resnet18_21.pth')\n",
    "cam10 = cam_from_model('aerial_small_auged_new_resnet18_14.pth')\n",
    "cam11 = cam_from_model('aerial_small_auged_new_resnet18_20.pth')\n",
    "cam12 = cam_from_model('aerial_small_auged_new_resnet18_22.pth')\n",
    "cam13 = cam_from_model('aerial_small_auged_new_resnet18_4.pth')\n",
    "cam14 = cam_from_model('aerial_small_auged_new_resnet18_0.pth')\n",
    "cam15 = cam_from_model('aerial_small_auged_new_resnet18_16.pth')\n",
    "cam16 = cam_from_model('aerial_small_auged_new_resnet18_2.pth')\n",
    "cam17 = cam_from_model('aerial_small_auged_new_resnet18_7.pth')\n",
    "cam18 = cam_from_model('aerial_small_auged_new_resnet18_5.pth')\n",
    "cam19 = cam_from_model('aerial_small_auged_new_resnet18_25.pth')\n",
    "cam20 = cam_from_model('aerial_small_auged_new_resnet18_17.pth')\n",
    "cam21 = cam_from_model('aerial_small_auged_new_resnet18_27.pth')\n",
    "cam22 = cam_from_model('aerial_small_auged_new_resnet18_19.pth')\n",
    "cam23 = cam_from_model('aerial_small_auged_new_resnet18_15.pth')\n",
    "cam24 = cam_from_model('aerial_small_auged_new_resnet18_3.pth')\n",
    "cam25 = cam_from_model('aerial_small_auged_new_resnet18_26.pth')\n",
    "cam26 = cam_from_model('aerial_small_auged_new_resnet18_9.pth')\n",
    "cam27 = cam_from_model('aerial_small_auged_new_resnet18_10.pth')\n",
    "cam28 = cam_from_model('aerial_small_auged_new_resnet18_18.pth')\n",
    "cam29 = cam_from_model('aerial_small_auged_new_resnet18_11.pth')\n",
    "masterCamList=[cam0,cam1,cam2,cam3,cam4,cam5,cam6,cam7,cam8,cam9,\n",
    "               cam10,cam11,cam12,cam13,cam14,cam15,cam16,cam17,cam18,cam19,\n",
    "               cam20,cam21,cam22,cam23,cam24,cam25,cam26,cam27,cam28,cam29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_0-ens_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlim/miniconda3/envs/wsod/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/nlim/miniconda3/envs/wsod/lib/python3.8/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/research/attention2boxes-master/activation_maps/base_cam.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cam = cam / np.max(cam)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_1-ens_1\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_2-ens_1\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_3-ens_1\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_0-ens_2\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_1-ens_2\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_2-ens_2\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_3-ens_2\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_0-ens_3\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_1-ens_3\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_2-ens_3\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_3-ens_3\n",
      "../results/aerial-imagery-resnet18-GradCam-batch-all-mode_0-ens_4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3593c7ff3d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthresholded_cam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mbox_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregionprops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mcambbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mcambbox_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/wsod/lib/python3.8/site-packages/skimage/measure/_label.py\u001b[0m in \u001b[0;36mlabel\u001b[0;34m(input, background, return_num, connectivity)\u001b[0m\n\u001b[1;32m    118\u001b[0m                            return_num=return_num, connectivity=connectivity)\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import skimage.transform as sktransform \n",
    "import PIL.ImageOps as IOps\n",
    "import PIL.ImageChops as ImChOps\n",
    "for ensSize in range(1,31):\n",
    "    for mode in range(0,4):\n",
    "        folder_name = f\"../results/aerial-imagery-resnet18-GradCam-batch-all-mode_{mode}-ens_{ensSize}\"\n",
    "        Path(folder_name).mkdir(parents=True, exist_ok=True)\n",
    "        print(folder_name)\n",
    "        for i in range(0,4342):\n",
    "            imgNo=i\n",
    "            oriPath=val_data.imgs[imgNo][0]\n",
    "            maskPath=val_data.imgs[imgNo][0].replace('classification','segmentation').replace('/val','')\n",
    "            (img,mylabel)=val_data.__getitem__(imgNo)\n",
    "            img_copy=np.array(img)\n",
    "            grayscale_cam=gscam_calc(masterCamList[0:ensSize],img,mylabel,mode)\n",
    "            tpr_fpr_list=[]\n",
    "            precision_recall_list=[]\n",
    "            gtmaskMap=cv2.imread(maskPath)\n",
    "            gtmaskMap = cv2.cvtColor(gtmaskMap, cv2.COLOR_BGR2GRAY)\n",
    "            gtmaskMap[0:,0]=0\n",
    "            gtmaskMap[0:,223]=0\n",
    "            gtmaskMap[0,0:]=0\n",
    "            gtmaskMap[223,0:]=0\n",
    "            gtmaskMap[gtmaskMap>1] = 1\n",
    "            gtbbox=np.zeros(gtmaskMap.shape)\n",
    "            gtbox_candidates = regionprops(label(gtmaskMap))\n",
    "            for ind_segMask in gtbox_candidates:\n",
    "                (y1,x1,y2,x2)=ind_segMask.bbox\n",
    "                gtbbox[y1:y2,x1:x2]=1\n",
    "            for idx, th in enumerate(np.arange(1.00, -0.01, -0.01), 1):\n",
    "                thresholded_cam = grayscale_cam.copy()\n",
    "                thresholded_cam[grayscale_cam < th] = 0\n",
    "                cam_on_image = show_cam_on_image(np.array(img_copy) / 255, thresholded_cam)\n",
    "                mask = thresholded_cam.copy()\n",
    "                mask[mask > 0] = 1\n",
    "                box_candidates = regionprops(label(mask))\n",
    "                cambbox=np.zeros(mask.shape)\n",
    "                cambbox_list=[]\n",
    "                for box_candidate in box_candidates:\n",
    "                    (y1,x1,y2,x2)=box_candidate.bbox\n",
    "                    cambbox[y1:y2,x1:x2]=1\n",
    "                tp=np.sum(np.logical_and(gtmaskMap==1,mask==1))\n",
    "                fn=np.sum(gtmaskMap==1)-tp\n",
    "                fp=np.sum(mask==1)-tp\n",
    "                tn=np.sum(np.logical_and(gtmaskMap==0,mask==0))\n",
    "                recall=tp/(tp+fn)\n",
    "                tpr=recall\n",
    "                precision=0\n",
    "                if((tp+fp)>0):\n",
    "                    precision=tp/(tp+fp)\n",
    "                fpr=0\n",
    "                if((fp+tn)>0):\n",
    "                    fpr=fp/(fp+tn)\n",
    "                precision_recall_list.append([precision,recall])\n",
    "                tpr_fpr_list.append([tpr,fpr])\n",
    "                cambbox_list=[]\n",
    "            pr_df=pd.DataFrame(precision_recall_list,columns=['Precision','Recall'])\n",
    "            tf_df=pd.DataFrame(tpr_fpr_list,columns=['TPR','FPR'])\n",
    "            csv_file=f\"{imgNo:04d}_{mylabel:02d}\"\n",
    "            pr_df.to_csv(f\"{folder_name}/pr_{csv_file}.csv\", index=False)\n",
    "            tf_df.to_csv(f\"{folder_name}/tf_{csv_file}.csv\", index=False)   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_cam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
